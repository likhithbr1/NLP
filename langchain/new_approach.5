import os
from sqlalchemy import create_engine
from langchain_community.utilities import SQLDatabase
from langchain_community.tools.sql_database.tool import (
    QuerySQLDatabaseTool,
    InfoSQLDatabaseTool,
    ListSQLDatabaseTool,
)
from langgraph.prebuilt import create_react_agent
from langchain import hub
from llama_cpp import Llama
from langchain_core.messages import HumanMessage
from langchain_core.outputs import ChatGeneration, ChatResult
from langchain_core.language_models.chat_models import BaseChatModel
from langchain_core.tools import Tool
from typing import List

# Step 1: DB Config
DB_USER = "root"
DB_PASSWORD = "admin"
DB_HOST = "localhost"
DB_PORT = 3306
DB_NAME = "chatbot"
DB_URI = f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Step 2: Load Mistral 7B (GGUF) using llama-cpp-python
class MistralLLM(BaseChatModel):
    def __init__(self, model_path: str, n_ctx: int = 2048, n_threads: int = 6, verbose: bool = True):
        print("‚è≥ Loading Mistral 7B model via llama.cpp...")
        object.__setattr__(self, "llama", Llama(
            model_path=model_path,
            n_ctx=n_ctx,
            n_threads=n_threads,
            verbose=verbose,
        ))
        print("‚úÖ Model loaded!")

    def _llm_type(self) -> str:
        return "mistral"

    def _generate(self, messages: List[HumanMessage], **kwargs) -> ChatResult:
        full_prompt = messages[-1].content if messages else ""
        output = self.llama(full_prompt, max_tokens=512, stop=["</s>", "SQL:"])
        return ChatResult(generations=[ChatGeneration(message=HumanMessage(content=output["choices"][0]["text"].strip()))])

    def bind_tools(self, tools):
        return self

# Set model path
MODEL_PATH = "mistral-7b-instruct-v0.2.Q4_K_M.gguf"

# Step 3: Setup SQL Tools manually (avoiding SQLDatabaseToolkit which needs a LangChain LLM)
llm = MistralLLM(model_path=MODEL_PATH)
db = SQLDatabase.from_uri(DB_URI)

tools = [
    QuerySQLDatabaseTool(db=db),
    InfoSQLDatabaseTool(db=db),
    ListSQLDatabaseTool(db=db),
]

# Step 4: Create ReAct Agent Executor
prompt_template = hub.pull("langchain-ai/sql-agent-system-prompt")
system_prompt = prompt_template.format(dialect="MySQL", top_k=5)
agent_executor = create_react_agent(llm, tools, prompt=system_prompt)

print("‚úÖ Agent executor is ready. You can now start streaming questions to it.")

# Step 5: Run user questions through agent and stream reasoning

def chat():
    while True:
        user_input = input("\nüîç Ask a question (or type 'exit'): ")
        if user_input.lower() in ["exit", "quit"]:
            print("üëã Exiting...")
            break

        for step in agent_executor.stream({"messages": [HumanMessage(content=user_input)]}, stream_mode="values"):
            print("\nüß† Step:", step["messages"][-1].content)

if __name__ == "__main__":
    chat()
