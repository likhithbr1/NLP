import os
from sqlalchemy import create_engine
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langgraph.prebuilt import create_react_agent
from langchain import hub
from llama_cpp import Llama
from langchain_core.messages import HumanMessage

# Step 1: DB Config
DB_USER = "root"
DB_PASSWORD = "admin"
DB_HOST = "localhost"
DB_PORT = 3306
DB_NAME = "chatbot"
DB_URI = f"mysql+pymysql://{DB_USER}:{DB_PASSWORD}@{DB_HOST}:{DB_PORT}/{DB_NAME}"

# Step 2: Load Mistral 7B (GGUF) using llama-cpp-python
class MistralLLM:
    def __init__(self, model_path: str, n_ctx: int = 2048, n_threads: int = 6, verbose: bool = True):
        print("⏳ Loading Mistral 7B model via llama.cpp...")
        self.llama = Llama(
            model_path=model_path,
            n_ctx=n_ctx,
            n_threads=n_threads,
            verbose=verbose,
        )
        print("✅ Model loaded!")

    def __call__(self, prompt: str) -> str:
        output = self.llama(prompt, max_tokens=512, stop=["</s>", "SQL:"])
        return output["choices"][0]["text"].strip()

# Set model path
MODEL_PATH = "mistral-7b-instruct-v0.2.Q4_K_M.gguf"

# Step 3: Setup SQL Toolkit
llm = MistralLLM(model_path=MODEL_PATH)
db = SQLDatabase.from_uri(DB_URI)
toolkit = SQLDatabaseToolkit(db=db, llm=llm)
tools = toolkit.get_tools()

# Step 4: Create ReAct Agent Executor
prompt_template = hub.pull("langchain-ai/sql-agent-system-prompt")
system_prompt = prompt_template.format(dialect="MySQL", top_k=5)
agent_executor = create_react_agent(llm, tools, prompt=system_prompt)

print("✅ Agent executor is ready. You can now start streaming questions to it.")

# Step 5: Run user questions through agent and stream reasoning

def chat():
    while True:
        user_input = input("\n🔍 Ask a question (or type 'exit'): ")
        if user_input.lower() in ["exit", "quit"]:
            print("👋 Exiting...")
            break

        for step in agent_executor.stream({"messages": [HumanMessage(content=user_input)]}, stream_mode="values"):
            print("\n🧠 Step:", step["messages"][-1].content)

if __name__ == "__main__":
    chat()
